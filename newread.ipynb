{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3347fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-import necessary packages after code execution state reset\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"Cancer2025exam.csv\")\n",
    "X = df.drop(columns=[\"V1\"])\n",
    "y = df[\"V1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a83dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a custom preprocessing wrapper to allow user-defined preprocessing\n",
    "class CustomPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, preprocessing_fn=None):\n",
    "        self.preprocessing_fn = preprocessing_fn\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing to fit here\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.preprocessing_fn:\n",
    "            return self.preprocessing_fn(X)\n",
    "        return X\n",
    "\n",
    "# Define a wrapper to enable class-balanced resampling inside the CV folds\n",
    "class ResampleWrapper(BaseEstimator):\n",
    "    def __init__(self, classifier):\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Equal sampling: downsample all classes to match the smallest class\n",
    "        df = pd.DataFrame(X)\n",
    "        df['label'] = y.values if hasattr(y, 'values') else y\n",
    "\n",
    "        min_class_size = df['label'].value_counts().min()\n",
    "        balanced_df = pd.concat([\n",
    "            resample(group, replace=False, n_samples=min_class_size, random_state=42)\n",
    "            for _, group in df.groupby('label')\n",
    "        ])\n",
    "        X_balanced = balanced_df.drop(columns='label').values\n",
    "        y_balanced = balanced_df['label'].values\n",
    "\n",
    "        self.classifier_ = clone(self.classifier)\n",
    "        self.classifier_.fit(X_balanced, y_balanced)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.classifier_.predict(X)\n",
    "\n",
    "# Define scorers for accuracy, sensitivity (macro recall), and specificity (macro TN rate)\n",
    "def specificity_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "    TN = []\n",
    "    FP = []\n",
    "    for i in range(len(cm)):\n",
    "        tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n",
    "        fp = cm[:, i].sum() - cm[i, i]\n",
    "        TN.append(tn)\n",
    "        FP.append(fp)\n",
    "    specificity = np.mean([tn / (tn + fp) if (tn + fp) > 0 else 0 for tn, fp in zip(TN, FP)])\n",
    "    return specificity\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'sensitivity_macro': make_scorer(recall_score, average='macro'),\n",
    "    'specificity_macro': make_scorer(specificity_score)\n",
    "}\n",
    "\n",
    "# Set up a reusable pipeline factory\n",
    "def create_pipeline(classifier, preprocessing_fn=None):\n",
    "    return Pipeline([\n",
    "        ('preprocess', CustomPreprocessor(preprocessing_fn)),\n",
    "        ('scale', StandardScaler()),\n",
    "        ('resample_clf', ResampleWrapper(classifier))\n",
    "    ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "406def20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ace_tools in c:\\users\\nils\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\Nils\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install ace_tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991b4ed0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ace_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Summarize\u001b[39;00m\n\u001b[0;32m     12\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(cv_results)[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_sensitivity_macro\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_specificity_macro\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mace_tools\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m; tools\u001b[38;5;241m.\u001b[39mdisplay_dataframe_to_user(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCV Performance Summary\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataframe\u001b[38;5;241m=\u001b[39mresults_df)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ace_tools'"
     ]
    }
   ],
   "source": [
    "# Example usage (user provides a classifier, e.g., RandomForestClassifier())\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = create_pipeline(clf)\n",
    "\n",
    "# Cross-validate\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = cross_validate(pipeline, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "# Summarize\n",
    "results_df = pd.DataFrame(cv_results)[['test_accuracy', 'test_sensitivity_macro', 'test_specificity_macro']]\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"CV Performance Summary\", dataframe=results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24f43cb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (192839687.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    restart channel = True\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "restart channel = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
