{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29948443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import deeplay as dl\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e4732d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nils\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | loss          | CrossEntropyLoss | 0      | eval \n",
      "1 | train_metrics | MetricCollection | 0      | train\n",
      "2 | val_metrics   | MetricCollection | 0      | train\n",
      "3 | test_metrics  | MetricCollection | 0      | train\n",
      "4 | model         | Sequential       | 19.7 K | train\n",
      "5 | loss_fn       | NLLLoss          | 0      | train\n",
      "6 | optimizer     | RMSprop          | 0      | train\n",
      "-----------------------------------------------------------\n",
      "19.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.7 K    Total params\n",
      "0.079     Total estimated model params size (MB)\n",
      "30        Modules in train mode\n",
      "1         Modules in eval mode\n",
      "C:\\Users\\Nils\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 50/50 [00:00<00:00, 67.29it/s, v_num=14]\n",
      "First 10 test predictions: [0, 0, 6, -9, 0, -2, 0, 8, 6, -9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import deeplay as dl\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Your existing functions (unchanged)\n",
    "def read_mnist_txt(file_path):\n",
    "    \"\"\"Read MNIST-like data from text file\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            parts = line.strip().split()\n",
    "            image_num = parts[0].strip('\"')\n",
    "            label = int(parts[1])\n",
    "            \n",
    "            # Validate label range\n",
    "            if label < -9 or label > 9:\n",
    "                raise ValueError(f\"Invalid label {label} found in the dataset.\")\n",
    "            \n",
    "            pixels = list(map(float, parts[2:]))\n",
    "            pixel_array = np.array(pixels).reshape(16, 16)\n",
    "            images.append(pixel_array)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for MNIST-like data\"\"\"\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Convert to PIL Image for compatibility with torchvision transforms\n",
    "        image = Image.fromarray(image.astype('float32'))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Shift labels to zero-based indexing\n",
    "        label = torch.tensor(label + 9, dtype=torch.long)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def create_cnn_model():\n",
    "    \"\"\"Create CNN model using deeplay\"\"\"\n",
    "    conv_base = dl.ConvolutionalNeuralNetwork(\n",
    "        in_channels=1, \n",
    "        hidden_channels=[16, 16, 32], \n",
    "        out_channels=32,\n",
    "    )\n",
    "    conv_base.blocks[2].pool.configure(torch.nn.MaxPool2d, kernel_size=2)\n",
    "\n",
    "    connector = dl.Layer(torch.nn.AdaptiveAvgPool2d, output_size=1)\n",
    "\n",
    "    # Update out_features to 19 for labels -9 to 9\n",
    "    dense_top = dl.MultiLayerPerceptron(\n",
    "        in_features=32,\n",
    "        hidden_features=[64],\n",
    "        out_features=19,  # Updated\n",
    "        out_activation=torch.nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "\n",
    "    return dl.Sequential(conv_base, connector, dense_top)\n",
    "\n",
    "def train_model(train_images, train_labels):\n",
    "    \"\"\"Train the CNN model and return the trained classifier.\"\"\"\n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    train_dataset = MNISTDataset(train_images, train_labels, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Create model\n",
    "    cnn = create_cnn_model()\n",
    "\n",
    "    # Define classifier\n",
    "    class MNISTClassifier(dl.Classifier):\n",
    "        def __init__(self, model, optimizer):\n",
    "            super().__init__(model=model, optimizer=optimizer)\n",
    "            self.loss_fn = torch.nn.NLLLoss()\n",
    "        \n",
    "        def training_step(self, batch, batch_idx):\n",
    "            x, y = batch\n",
    "            y_hat = self.model(x)\n",
    "            loss = self.loss_fn(y_hat, y)\n",
    "            return loss\n",
    "\n",
    "    classifier = MNISTClassifier(\n",
    "        model=cnn,\n",
    "        optimizer=dl.RMSprop(lr=0.001)\n",
    "    ).create()\n",
    "\n",
    "    # Train the model\n",
    "    trainer = dl.Trainer(max_epochs=20, accelerator=\"auto\")\n",
    "    trainer.fit(classifier, train_loader)\n",
    "\n",
    "    return classifier\n",
    "\n",
    "\n",
    "# Prediction function\n",
    "def predict_with_model(classifier, test_images):\n",
    "    \"\"\"Use trained classifier to make predictions on test_images.\"\"\"\n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    # Dummy labels for test set\n",
    "    test_dataset = MNISTDataset(test_images, np.zeros(len(test_images)), transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Get predictions\n",
    "    test_labels = []\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, _ in test_loader:\n",
    "            y_hat = classifier.model(x)\n",
    "            preds = torch.argmax(y_hat, dim=1)\n",
    "            test_labels.extend((preds - 9).cpu().numpy().tolist())  # Adjust if needed\n",
    "\n",
    "    return test_labels\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    images, labels = read_mnist_txt(\"Numbers.txt\")\n",
    "\n",
    "    train_images, test_images, train_labels, _ = train_test_split(\n",
    "        images, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    classifier = train_model(train_images, train_labels)\n",
    "    predictions = predict_with_model(classifier, test_images)\n",
    "\n",
    "    print(\"First 10 test predictions:\", predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d6486e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def cross_validate(images, labels, train_fn, predict_fn, k_folds=5, metric_fn=accuracy_score):\n",
    "    \"\"\"\n",
    "    Generic cross-validation.\n",
    "\n",
    "    Args:\n",
    "        images (np.ndarray): Image data.\n",
    "        labels (np.ndarray): Corresponding labels.\n",
    "        train_fn (callable): Function to train a model. Signature: (train_images, train_labels) -> model\n",
    "        predict_fn (callable): Function to predict. Signature: (model, test_images) -> predictions\n",
    "        k_folds (int): Number of folds (default 5).\n",
    "        metric_fn (callable): Evaluation metric function. Signature: (true_labels, predicted_labels) -> float\n",
    "\n",
    "    Returns:\n",
    "        List of scores for each fold.\n",
    "    \"\"\"\n",
    "    all_scores = []\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(images)):\n",
    "        print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "\n",
    "        train_images, val_images = images[train_idx], images[val_idx]\n",
    "        train_labels, val_labels = labels[train_idx], labels[val_idx]\n",
    "\n",
    "        # Train and predict\n",
    "        model = train_fn(train_images, train_labels)\n",
    "        predictions = predict_fn(model, val_images)\n",
    "\n",
    "        # Score\n",
    "        score = metric_fn(val_labels, predictions)\n",
    "        print(f\"Fold {fold + 1} Score: {score:.4f}\")\n",
    "        all_scores.append(score)\n",
    "\n",
    "    print(\"\\nCross-validation results:\")\n",
    "    print(f\"Mean score: {np.mean(all_scores):.4f}\")\n",
    "    print(f\"Std deviation: {np.std(all_scores):.4f}\")\n",
    "\n",
    "    return all_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa9ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Training\" function for k-NN (just returns training data and labels)\n",
    "def train_knn_model(train_images, train_labels, k=3, norm=2):\n",
    "    return {\n",
    "        'train_images': train_images,\n",
    "        'train_labels': train_labels,\n",
    "        'k': k,\n",
    "        'norm': norm\n",
    "    }\n",
    "\n",
    "# Prediction function for k-NN\n",
    "def predict_knn(model, test_images):\n",
    "    train_images = model['train_images']\n",
    "    train_labels = model['train_labels']\n",
    "    k = model['k']\n",
    "    norm = model['norm']\n",
    "    \n",
    "    predictions = []\n",
    "    for image in test_images:\n",
    "        distances = [(\n",
    "            np.linalg.norm(train_image - image, ord=norm), label\n",
    "        ) for train_image, label in zip(train_images, train_labels)]\n",
    "        \n",
    "        neighbors = sorted(distances, key=lambda x: x[0])[:k]\n",
    "        labels = [label for _, label in neighbors]\n",
    "        predicted = max(labels, key=labels.count)\n",
    "        predictions.append(predicted)\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "744f55aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "Fold 1 Score: 0.8950\n",
      "\n",
      "Fold 2/5\n",
      "Fold 2 Score: 0.9300\n",
      "\n",
      "Fold 3/5\n",
      "Fold 3 Score: 0.9225\n",
      "\n",
      "Fold 4/5\n",
      "Fold 4 Score: 0.9250\n",
      "\n",
      "Fold 5/5\n",
      "Fold 5 Score: 0.9175\n",
      "\n",
      "Cross-validation results:\n",
      "Mean score: 0.9180\n",
      "Std deviation: 0.0122\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    images, labels = read_mnist_txt(\"Numbers.txt\")\n",
    "\n",
    "    # Normalize if needed\n",
    "    flat_images = images.reshape(len(images), -1)\n",
    "    scaler = StandardScaler()\n",
    "    flat_images = scaler.fit_transform(flat_images)\n",
    "\n",
    "    # Create partial functions for fixed k and norm\n",
    "    from functools import partial\n",
    "    k = 5\n",
    "    norm = 2\n",
    "    train_fn = partial(train_knn_model, k=k, norm=norm)\n",
    "\n",
    "    scores = cross_validate(\n",
    "        images=flat_images,\n",
    "        labels=labels,\n",
    "        train_fn=train_fn,\n",
    "        predict_fn=predict_knn,\n",
    "        k_folds=5,\n",
    "        metric_fn=accuracy_score\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5af08257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nils\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | loss          | CrossEntropyLoss | 0      | eval \n",
      "1 | train_metrics | MetricCollection | 0      | train\n",
      "2 | val_metrics   | MetricCollection | 0      | train\n",
      "3 | test_metrics  | MetricCollection | 0      | train\n",
      "4 | model         | Sequential       | 19.7 K | train\n",
      "5 | loss_fn       | NLLLoss          | 0      | train\n",
      "6 | optimizer     | RMSprop          | 0      | train\n",
      "-----------------------------------------------------------\n",
      "19.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.7 K    Total params\n",
      "0.079     Total estimated model params size (MB)\n",
      "30        Modules in train mode\n",
      "1         Modules in eval mode\n",
      "C:\\Users\\Nils\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "Epoch 19: 100%|██████████| 50/50 [00:00<00:00, 61.44it/s, v_num=22]\n",
      "Fold 1 Score: 0.8450\n",
      "\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nils\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | loss          | CrossEntropyLoss | 0      | eval \n",
      "1 | train_metrics | MetricCollection | 0      | train\n",
      "2 | val_metrics   | MetricCollection | 0      | train\n",
      "3 | test_metrics  | MetricCollection | 0      | train\n",
      "4 | model         | Sequential       | 19.7 K | train\n",
      "5 | loss_fn       | NLLLoss          | 0      | train\n",
      "6 | optimizer     | RMSprop          | 0      | train\n",
      "-----------------------------------------------------------\n",
      "19.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.7 K    Total params\n",
      "0.079     Total estimated model params size (MB)\n",
      "30        Modules in train mode\n",
      "1         Modules in eval mode\n",
      "C:\\Users\\Nils\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 50/50 [00:00<00:00, 73.41it/s, v_num=23]\n",
      "Fold 2 Score: 0.8775\n",
      "\n",
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nils\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | loss          | CrossEntropyLoss | 0      | eval \n",
      "1 | train_metrics | MetricCollection | 0      | train\n",
      "2 | val_metrics   | MetricCollection | 0      | train\n",
      "3 | test_metrics  | MetricCollection | 0      | train\n",
      "4 | model         | Sequential       | 19.7 K | train\n",
      "5 | loss_fn       | NLLLoss          | 0      | train\n",
      "6 | optimizer     | RMSprop          | 0      | train\n",
      "-----------------------------------------------------------\n",
      "19.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.7 K    Total params\n",
      "0.079     Total estimated model params size (MB)\n",
      "30        Modules in train mode\n",
      "1         Modules in eval mode\n",
      "C:\\Users\\Nils\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 50/50 [00:00<00:00, 69.34it/s, v_num=24]\n",
      "Fold 3 Score: 0.8550\n",
      "\n",
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nils\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | loss          | CrossEntropyLoss | 0      | eval \n",
      "1 | train_metrics | MetricCollection | 0      | train\n",
      "2 | val_metrics   | MetricCollection | 0      | train\n",
      "3 | test_metrics  | MetricCollection | 0      | train\n",
      "4 | model         | Sequential       | 19.7 K | train\n",
      "5 | loss_fn       | NLLLoss          | 0      | train\n",
      "6 | optimizer     | RMSprop          | 0      | train\n",
      "-----------------------------------------------------------\n",
      "19.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.7 K    Total params\n",
      "0.079     Total estimated model params size (MB)\n",
      "30        Modules in train mode\n",
      "1         Modules in eval mode\n",
      "C:\\Users\\Nils\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 50/50 [00:00<00:00, 60.30it/s, v_num=25]\n",
      "Fold 4 Score: 0.9275\n",
      "\n",
      "Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nils\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | loss          | CrossEntropyLoss | 0      | eval \n",
      "1 | train_metrics | MetricCollection | 0      | train\n",
      "2 | val_metrics   | MetricCollection | 0      | train\n",
      "3 | test_metrics  | MetricCollection | 0      | train\n",
      "4 | model         | Sequential       | 19.7 K | train\n",
      "5 | loss_fn       | NLLLoss          | 0      | train\n",
      "6 | optimizer     | RMSprop          | 0      | train\n",
      "-----------------------------------------------------------\n",
      "19.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.7 K    Total params\n",
      "0.079     Total estimated model params size (MB)\n",
      "30        Modules in train mode\n",
      "1         Modules in eval mode\n",
      "C:\\Users\\Nils\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 50/50 [00:00<00:00, 70.81it/s, v_num=26]\n",
      "Fold 5 Score: 0.8925\n",
      "\n",
      "Cross-validation results:\n",
      "Mean score: 0.8795\n",
      "Std deviation: 0.0292\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    images, labels = read_mnist_txt(\"Numbers.txt\")\n",
    "\n",
    "    scores = cross_validate(\n",
    "        images=images,\n",
    "        labels=labels,\n",
    "        train_fn=train_model,\n",
    "        predict_fn=predict_with_model,\n",
    "        k_folds=5,\n",
    "        metric_fn=accuracy_score  # Optional, default already\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
